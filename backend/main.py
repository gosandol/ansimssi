import os
from dotenv import load_dotenv
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Optional
from tavily import TavilyClient
import google.generativeai as genai
from kdca_service import KdcaService

# Load environment variables
dotenv_path = os.path.join(os.path.dirname(__file__), '.env')
load_dotenv(dotenv_path)

app = FastAPI()

# Configure CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Initialize Clients
tavily_api_key = os.getenv("TAVILY_API_KEY")
gemini_api_key = os.getenv("GEMINI_API_KEY")

# Initialize Services
tavily_client = TavilyClient(api_key=tavily_api_key) if tavily_api_key else None
kdca_service = KdcaService()

if gemini_api_key:
    genai.configure(api_key=gemini_api_key)
    model = genai.GenerativeModel('gemini-2.0-flash')
else:
    model = None

class SearchRequest(BaseModel):
    query: str
    thread_id: Optional[str] = None

class Source(BaseModel):
    title: str
    url: str
    content: str

class SearchResponse(BaseModel):
    answer: str
    disclaimer: str
    sources: List[Source]
    images: List[str]
    related_questions: List[str]

@app.post("/api/search", response_model=SearchResponse)
async def search(request: SearchRequest):
    if not tavily_client:
        print("Error: Tavily Client not initialized (Key missing?)")
        raise HTTPException(status_code=500, detail="Tavily Key missing")
    if not model:
        print("Error: Gemini Model not initialized (Key missing?)")
        raise HTTPException(status_code=500, detail="Gemini Key missing")

    try:
        # 0. RAG: Check Medical Knowledge Base first
        rag_context = ""
        matched_topics = []
        try:
            # Load data if not loaded (basic caching)
            # In production, load this once at startup
            json_path = os.path.join(os.path.dirname(__file__), 'data', 'medical_data.json')
            if os.path.exists(json_path):
                import json
                with open(json_path, 'r', encoding='utf-8') as f:
                    medical_knowledge = json.load(f)
                
                # Simple Keyword Matching
                for item in medical_knowledge:
                    for keyword in item.get('keywords', []):
                        if keyword in request.query:
                            rag_context += f"\n\n[OFFICIAL HEALTH GUIDELINE]\n{item['content']}"
                            matched_topics.append(item['id'])
                            break # Match once per item
        except Exception as e:
            print(f"RAG Error: {e}")

        # 1. Search with Tavily
        print(f"Searching for: {request.query}")
        search_result = tavily_client.search(query=request.query, search_depth="basic", include_images=True)
        results = search_result.get("results", [])
        images = search_result.get("images", [])
        
        # Format context (RAG + Search Results)
        search_context = "\n\n".join([
            f"Source '{r['title']}': {r['content']}" 
            for r in results[:5] 
        ])
        
        full_context = f"{rag_context}\n\n=== WEB SEARCH RESULTS ===\n{search_context}"

        # 2. Generate Answer with Gemini
        system_prompt = """You are Ansimssi (ì•ˆì‹¬ì”¨), a professional "AI Principal Doctor" (AI ì£¼ì¹˜ì˜) and safety caregiver for Korean users.
        
        TASK:
        0. **CRISIS PROTOCOL (HIGHEST PRIORITY)**:
           - IF the query implies **suicide, self-harm, or immediate life-threatening emergency** (e.g., "ì£½ê³  ì‹¶ì–´", "ìì‚´", "ìˆ¨ì„ ëª» ì‰¬ê² ì–´", "ì‚´ë ¤ì¤˜"):
             Output specific emergency guidance:
             "ìƒëª…ì˜ ì†Œì¤‘í•¨ì„ ìŠì§€ ë§ˆì„¸ìš”. ì§€ê¸ˆ ì¦‰ì‹œ ë„ì›€ì´ í•„ìš”í•˜ë‹¤ë©´ ì•„ë˜ ë²ˆí˜¸ë¡œ ì—°ë½í•˜ì„¸ìš”.
             * ğŸ†˜ **119** (ì‘ê¸‰ìƒí™©)
             * ğŸ“ **109** (24ì‹œê°„ ìì‚´ì˜ˆë°© ìƒë‹´ì „í™”)
             * â˜ï¸ **1577-0199** (ì •ì‹ ê±´ê°• ìƒë‹´ì „í™”)
             ë‹¹ì‹ ì€ í˜¼ìê°€ ì•„ë‹™ë‹ˆë‹¤. ì „ë¬¸ê°€ì˜ ë„ì›€ì„ ë°›ìœ¼ì„¸ìš”."
             (Skip the rest of the logic)

        1. Answer the user's query **based ONLY on the provided context**. **Do NOT hallucinate** or invent medical treatments not present in the sources.
        2. PRIORITIZE information labeled [OFFICIAL HEALTH GUIDELINE] over web search results.
        3. Identity: If asked "Who are you?", answer: "ë„¤, ì €ëŠ” ë‹¹ì‹ ì˜ AI ì£¼ì¹˜ì˜ ê²¸ ì•ˆì „ëŒë´„ì´ ì•ˆì‹¬ì”¨ì…ë‹ˆë‹¤. ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"
        4. STRUCTURE:
           - Provide a comprehensive, empathetic answer first.
           - **MANDATORY**: End every health/medical/safety advice with a specific section:
             
             **ì•ˆì‹¬ì”¨ì˜ ìµœì¢… ê¶Œê³ :**
             - [Clear, actionable advice 1]
             - [Clear, actionable advice 2]
             - (Optional) "ì „ë¬¸ ì˜ë£Œì§„ê³¼ì˜ ìƒë‹´ì„ ê¶Œì¥í•©ë‹ˆë‹¤."
        
        5. Disclaimer Logic (Return 'disclaimer_type' field):
           - If the query implies medical/health advice -> "medical"
           - Otherwise -> "general"
        
        OUTPUT FORMAT (JSON ONLY):
        {
            "answer": "Your answer in Korean Markdown...",
            "disclaimer_type": "medical" | "general"
        }
        
        Be authoritative yet kind. Use medical terminology correctly but explain it simply.
        ALWAYS answer in KOREAN.
        """
        
        prompt = f"{system_prompt}\n\nContext:\n{full_context}\n\nQuery: {request.query}"
        
        response = model.generate_content(prompt, generation_config={"response_mime_type": "application/json"})
        
        import json
        
        # Hardcoded Disclaimers to prevent Hallucinations/Typos
        DISCLAIMER_MEDICAL = "ë³¸ ë‹µë³€ì€ ë³´ê±´ë³µì§€ë¶€ì˜ ë¹„ì˜ë£Œ ê±´ê°•ê´€ë¦¬ì„œë¹„ìŠ¤ ê°€ì´ë“œë¼ì¸ì„ ì¤€ìˆ˜í•˜ë©°, ì˜í•™ì  ì§„ë‹¨, ì¹˜ë£Œ, ì²˜ë°©ì„ ëŒ€ì‹ í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì œê³µë˜ëŠ” ì •ë³´ëŠ” ì°¸ê³ ìš©ì´ë©°, ì •í™•í•œ ì˜í•™ì  ì†Œê²¬ì€ ë°˜ë“œì‹œ ì „ë¬¸ì˜ì™€ ìƒì˜í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤."
        DISCLAIMER_GENERAL = "ì œê³µëœ ì •ë³´ëŠ” ì°¸ê³ ìš©ì´ë©°, ì •í™•í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."

        try:
            response_json = json.loads(response.text)
            answer = response_json.get("answer", "")
            dis_type = response_json.get("disclaimer_type", "general")
            
            if dis_type == "medical":
                disclaimer = DISCLAIMER_MEDICAL
            else:
                disclaimer = DISCLAIMER_GENERAL
                
        except json.JSONDecodeError:
            print("Warning: Failed to parse JSON, falling back to raw text")
            answer = response.text
            disclaimer = DISCLAIMER_GENERAL

        # 3. Related Questions (Mock for now to save latency/tokens)
        related_questions = [
            f"More details about {request.query}",
            f"Safety tips for {request.query}",
            f"Recent news on {request.query}"
        ]

        # Map sources
        sources = [
            Source(title=r['title'], url=r['url'], content=r['content']) 
            for r in results[:5]
        ]

        return SearchResponse(
            answer=answer,
            disclaimer=disclaimer,
            sources=sources,
            images=images,
            related_questions=related_questions
        )

    except Exception as e:
        print(f"Error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/health-data")
async def get_health_data():
    try:
        data = kdca_service.get_health_data()
        return data
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/")
def read_root():
    return {"status": "ok", "message": "Ansimssi AI Backend (Gemini) is running"}
